{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAPgHq_ZzWtg"
   },
   "source": [
    "   Predict the onset of diabetes based on Diagnostic Measures\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lF43fD0UWBJE"
   },
   "source": [
    "## DATA\n",
    "\n",
    "Source of the data\n",
    "The dataset is collected from \"kaggle datasets download -d uciml/pima-indians-diabetes-database\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrivesYtWSgq"
   },
   "source": [
    "### Data Description\n",
    "The Dataset consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dA8wvMIjzWtz"
   },
   "source": [
    "## Attributes\n",
    "##### \"Pregnancies\"    \n",
    "Number of times pregnant\n",
    "##### \"Glucose\"  \n",
    "Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "##### \"BloodPressure\" \n",
    "Diastolic blood pressure (mm Hg)\n",
    "##### \"SkinThickness\"   \n",
    "Triceps skin fold thickness (mm)\n",
    "##### \"Insulin\"       \n",
    "2-Hour serum insulin (m--> u U/ml)\n",
    "##### \"BMI\"          \n",
    "Body mass index (weight in kg/(height in m)^2)\n",
    "##### \"DiabetesPedigreeFunction\"   \n",
    "Diabetes pedigree function\n",
    "##### \"Age\"        \n",
    "Age (years)\n",
    "##### \"Outcome\"     \n",
    "Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8X5Y8wJ8zWt9"
   },
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rrRXsTOQzWuC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQTDbwkczWug"
   },
   "source": [
    "# Loading Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OlpmKLbhzWul"
   },
   "outputs": [],
   "source": [
    "filename = 'diabetes.csv'\n",
    "data=pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyI1xAo1zWu3"
   },
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dc91plOJzWu-",
    "outputId": "4bf12545-5b51-47aa-9f0b-fb6dcc042b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxpNlGbhzWvg"
   },
   "source": [
    "# Getting number of rows and columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k-KS35TPzWvl",
    "outputId": "64e1d5a0-1ad1-4ef0-e558-79c7d54d6059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2vTUD9pzWv9"
   },
   "source": [
    "# Getting the whole information about Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "uEQLP8wBzWwF",
    "outputId": "2927cbe3-8663-4fa5-aab9-365d3443b71e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tBlX7p3zWwx"
   },
   "source": [
    "# Visualize the data\n",
    "Visualizing the dataset by plotting the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "colab_type": "code",
    "id": "YeutqDEDzWw0",
    "outputId": "b38b2daf-0a58-48e4-d427-f264eec20ffc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAAJOCAYAAADcTTxQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21333c216a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(bins=50, figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W48UbNYqW_jE"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "8gT4o4EMzWwb"
   },
   "source": [
    "# Preprocessing the dataset\n",
    "This is a binary classification problem where all of the attributes are numeric and have different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "08JV0J52Wmhy"
   },
   "source": [
    "## Getting the correlation matrix \n",
    "The correlation matrix is an important tool to understand the correlation between the different characteristics. The values range from -1 to 1 and the closer a value is to 1 the better correlation there is between two characteristics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "YTvrT54YzWwk",
    "outputId": "6680668d-1276-488d-e32c-25406284a7bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
       "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
       "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
       "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
       "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
       "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
       "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
       "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
       "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
       "Glucose                   0.331357  0.221071                  0.137337   \n",
       "BloodPressure             0.088933  0.281805                  0.041265   \n",
       "SkinThickness             0.436783  0.392573                  0.183928   \n",
       "Insulin                   1.000000  0.197859                  0.185071   \n",
       "BMI                       0.197859  1.000000                  0.140647   \n",
       "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
       "Age                      -0.042163  0.036242                  0.033561   \n",
       "Outcome                   0.130548  0.292695                  0.173844   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.544341  0.221898  \n",
       "Glucose                   0.263514  0.466581  \n",
       "BloodPressure             0.239528  0.065068  \n",
       "SkinThickness            -0.113970  0.074752  \n",
       "Insulin                  -0.042163  0.130548  \n",
       "BMI                       0.036242  0.292695  \n",
       "DiabetesPedigreeFunction  0.033561  0.173844  \n",
       "Age                       1.000000  0.238356  \n",
       "Outcome                   0.238356  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZJ_WOg_zWxB"
   },
   "source": [
    "An important thing I notice in the dataset is the fact that some people have null (zero) values for some of the features: it's not quite possible to have 0 as BMI or for the blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OH7qP5FZzWxE"
   },
   "source": [
    "## Data cleaning\n",
    " We have noticed from the previous analysis that some patients have missing data for some of the features. Machine learning algorithms don't work very well when the data is missing so we have to find a solution to \"clean\" the data we have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGG7ITU2Yxff"
   },
   "source": [
    "\n",
    "#### Check NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "M6LZ8duezWxK",
    "outputId": "f6cb899c-3b7a-4f28-f3e6-efe40eee16b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJ2CL1wBzWxX"
   },
   "source": [
    "The null rows are absent or replaced with zero by visualization we can see this.\n",
    "So we replace all the values by median (not by mean because it may contain outleirs also)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bJn_s54N1q_R"
   },
   "source": [
    "Describe the whole summary of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "VIKUF8hQALeX",
    "outputId": "c45658c1-7c08-4f7e-941d-178f8be8f0ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vS7UmjWRzWxa"
   },
   "outputs": [],
   "source": [
    "# Calculate the median value for BMI\n",
    "median_bmi = data['BMI'].median()\n",
    "# Substitute it in the BMI column of the\n",
    "# dataset where values are 0\n",
    "data['BMI'] = data['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bQ8bZOXzzWxl"
   },
   "outputs": [],
   "source": [
    "# Calculate the median value for BloodPressure\n",
    "median_bloodp = data['BloodPressure'].median()\n",
    "# Substitute it in the BloodPressure column of the\n",
    "# dataset where values are 0\n",
    "data['BloodPressure'] = data['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TH_Vq8tCzWxv"
   },
   "outputs": [],
   "source": [
    "# Calculate the median value for Glucose\n",
    "median_plglcconc = data['Glucose'].median()\n",
    "# Substitute it in the Glucose column of the\n",
    "# dataset where values are 0\n",
    "data['Glucose'] = data['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hnF83GtdzWyJ"
   },
   "outputs": [],
   "source": [
    "# Calculate the median value for SkinThick\n",
    "median_skinthick = data['SkinThickness'].median()\n",
    "# Substitute it in the SkinThick column of the\n",
    "# dataset where values are 0\n",
    "data['SkinThickness'] = data['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aAJ26ADVzWyf"
   },
   "outputs": [],
   "source": [
    "# Calculate the median value for Insulin\n",
    "median_twohourserins = data['Insulin'].median()\n",
    "# Substitute it in the Insulin column of the\n",
    "# dataset where values are 0\n",
    "data['Insulin'] = data['Insulin'].replace(\n",
    "    to_replace=0, value=median_twohourserins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "P7_AlCYUAdn-",
    "outputId": "59847432-8d82-429c-8163-ff19315a55eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.656250</td>\n",
       "      <td>72.386719</td>\n",
       "      <td>27.334635</td>\n",
       "      <td>94.652344</td>\n",
       "      <td>32.450911</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.438286</td>\n",
       "      <td>12.096642</td>\n",
       "      <td>9.229014</td>\n",
       "      <td>105.547598</td>\n",
       "      <td>6.875366</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  121.656250      72.386719      27.334635   94.652344   \n",
       "std       3.369578   30.438286      12.096642       9.229014  105.547598   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.750000      64.000000      23.000000   30.500000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   31.250000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.450911                  0.471876   33.240885    0.348958  \n",
       "std      6.875366                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iifCMt_c2RK_"
   },
   "source": [
    "### Finding Outliers \n",
    "After applying the mean and median  on the zero values in the given  dataset we have observed that the mean and median of the whole is data is not same which  represents that there are outliers in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "colab_type": "code",
    "id": "mhmAXtCHMiwZ",
    "outputId": "44ef4b0f-2732-4bf7-b7b3-ab1ba9aef3c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                    AxesSubplot(0.125,0.657941;0.227941x0.222059)\n",
       "Glucose                     AxesSubplot(0.398529,0.657941;0.227941x0.222059)\n",
       "BloodPressure               AxesSubplot(0.672059,0.657941;0.227941x0.222059)\n",
       "SkinThickness                  AxesSubplot(0.125,0.391471;0.227941x0.222059)\n",
       "Insulin                     AxesSubplot(0.398529,0.391471;0.227941x0.222059)\n",
       "BMI                         AxesSubplot(0.672059,0.391471;0.227941x0.222059)\n",
       "DiabetesPedigreeFunction          AxesSubplot(0.125,0.125;0.227941x0.222059)\n",
       "Age                            AxesSubplot(0.398529,0.125;0.227941x0.222059)\n",
       "Outcome                        AxesSubplot(0.672059,0.125;0.227941x0.222059)\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.plot(kind= 'box' , subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(10,8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7MMJcVQONqd"
   },
   "source": [
    "#### Z-Score\n",
    "The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\n",
    "\n",
    "The intuition behind Z-score is to describe any data point by finding their relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\n",
    "\n",
    "Below code uses Z-score function defined in scipy library to detect the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "aNk49W74OneQ",
    "outputId": "0472cae0-c7cb-45c7-bf32-3bec85460f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.86604475  0.03198993 ...,  0.46849198  1.4259954\n",
      "   1.36589591]\n",
      " [ 0.84488505  1.20506583  0.5283186  ...,  0.36506078  0.19067191\n",
      "   0.73212021]\n",
      " [ 1.23388019  2.01666174  0.69376149 ...,  0.60439732  0.10558415\n",
      "   1.36589591]\n",
      " ..., \n",
      " [ 0.3429808   0.02157407  0.03198993 ...,  0.68519336  0.27575966\n",
      "   0.73212021]\n",
      " [ 0.84488505  0.14279979  1.02464727 ...,  0.37110101  1.17073215\n",
      "   1.36589591]\n",
      " [ 0.84488505  0.94206766  0.19743282 ...,  0.47378505  0.87137393\n",
      "   0.73212021]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(data))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLkMKfR4O2XX"
   },
   "source": [
    "Now the below code define a threshold to identify outliers from the above output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "g4AOrhtWRjx8",
    "outputId": "79f0d9ac-f55e-40be-caf6-bcacfa0f5d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  4,   8,  13,  18,  43,  45,  57,  58,  88, 106, 111, 120, 120,\n",
      "       123, 125, 125, 153, 159, 177, 177, 186, 220, 228, 228, 247, 286,\n",
      "       298, 330, 370, 370, 371, 392, 395, 409, 415, 445, 445, 445, 453,\n",
      "       455, 459, 486, 549, 579, 584, 593, 597, 621, 645, 655, 666, 673,\n",
      "       684, 691, 695, 753], dtype=int64), array([6, 4, 4, 2, 2, 6, 3, 6, 0, 2, 4, 3, 5, 7, 2, 5, 4, 0, 2, 5, 4, 4, 4,\n",
      "       6, 4, 4, 0, 6, 4, 6, 6, 4, 6, 4, 4, 3, 5, 6, 7, 0, 7, 4, 2, 3, 4, 6,\n",
      "       2, 6, 4, 4, 7, 5, 7, 2, 4, 4], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "a = np.where(z > threshold)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47tchUxhU291"
   },
   "source": [
    "The first array contains the list of row numbers and second array respective column numbers, which mean z[55][1] have a Z-score higher than 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQ_0SHfbQziX"
   },
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCZHo8MWUDcI"
   },
   "source": [
    "Now, below code uses the outliers that were found above and replaces them with the Median value of their respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D6JRQM_ARFis"
   },
   "outputs": [],
   "source": [
    "column_names = list(data.columns.values)\n",
    "for i in range(0,a[0].size):\n",
    "    row=a[0][i]\n",
    "    col=a[1][i]\n",
    "    colname = column_names[col]\n",
    "    median = data[colname].median()\n",
    "    currValue = data.loc[row,colname]\n",
    "    data[colname] = data[colname].replace(\n",
    "    to_replace=currValue,value=median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HM6WIrzFzWyt"
   },
   "source": [
    "## Splitting the Dataset\n",
    "Here we are splitting the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TPrSbnyHzWyw"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#seperate outcome and other features as labels and features\n",
    "features = data[data.columns[:8]]  \n",
    "labels = data[\"Outcome\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.3,\n",
    "    random_state=62,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision \n",
    "It is true positive values divided by true positives and false positives  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall \n",
    "It is true positive values divided by true positives and false negatives it represents completeness whether we have completed all the classes or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F measure\n",
    "The F1 score (also F-score or F-measure) is a measure of a test's accuracy. The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07f_LRCiciUH"
   },
   "source": [
    "# Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0j_VzaN5xa0"
   },
   "source": [
    "## Decision tree classification \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpYuHiUVkTcC"
   },
   "source": [
    "\n",
    "Decision Tree Classifier, repetitively divides the working area(plot) into sub part by identifying lines. (repetitively because there may be two distant regions of same class divided by other).\n",
    "** Decision tree builds classification or regression models in the form of a tree structure.** It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.\n",
    "Dividing efficiently based on maximum information gain is key to decision tree classifier. However, in real world with millions of data dividing into pure class in practically not feasible (it may take longer training time) and so we stop at points in nodes of tree when fulfilled with certain parameters (for example impurity percentage).\n",
    "\n",
    "Here we are applying the decision tree classification  using the **sklearn** library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "qTXws0vVPFHp",
    "outputId": "ba914192-f76e-412b-a55a-b3385856a008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[103  39]\n",
      " [ 46  43]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.73      0.71       142\n",
      "          1       0.52      0.48      0.50        89\n",
      "\n",
      "avg / total       0.63      0.63      0.63       231\n",
      "\n",
      "accuracy_score: \n",
      " 0.632034632035\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,y_pred))\n",
    "print('accuracy_score: \\n',clf.score(X=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3sLl4xhFWWb"
   },
   "source": [
    "## KNN classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "heq8LdqifpKc",
    "outputId": "c9975f9c-a81f-4db6-9d09-38f356d0d387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[123  19]\n",
      " [ 51  38]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.87      0.78       142\n",
      "          1       0.67      0.43      0.52        89\n",
      "\n",
      "avg / total       0.69      0.70      0.68       231\n",
      "\n",
      "accuracy_score: \n",
      " 0.69696969697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = 4)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,y_pred))\n",
    "print('accuracy_score: \\n',knn.score(X=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gCT31c4OcRY"
   },
   "source": [
    "Here weare using the class labels of the nearest neighbours  to predict the unknown class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yW86wzQ4QFoz"
   },
   "source": [
    "First we **find the euclidean distance** between two points to find the distance between the two points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9xGobCZQW28"
   },
   "source": [
    "Then  determine the class from the nearest neighbours list  by taking the majority vote of the class from the k nearest neighbours  and weight the vote according to the distance.\n",
    "\n",
    "**weight factor, w = 1/d2 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HN3gPoQDUhp0"
   },
   "source": [
    "The problem arrives in KNN if value of k is not choosen appropriately.\n",
    "If the k is too large ( approximately equal to the size of the dataset) then it will give the constant output, if it is too small then the output is sensitive to noise points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnb62EkuUjqP"
   },
   "source": [
    "Here  we are taking  the value of k=4 and the obtained more accuracy score  if we increase the value of k to 5 then  accuracy reduces and on decreasing the value of k the accuracy is also decreasing. So the approriate value of k is 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDe9vDf-hUFO"
   },
   "source": [
    "##SVM clasification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bNde0YONiKih"
   },
   "source": [
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side\n",
    "\n",
    "**Learning the Maximum Margin Classifier**\n",
    "\n",
    "Given a guess for w and b\n",
    "Compute whether all data points in correct half-planes\n",
    "\n",
    "  * Compute the width of the margin\n",
    "  * Search the space of ws and bs to find the widest margin that matches all data points\n",
    "\n",
    "Correctly classify all training data\n",
    "\n",
    "     wx(i) + 1 >= 1 ; if y(i) = +1\n",
    "     wx(i) + 1 <= 1 ; if y(i) = -1\n",
    "     y(i)(wx(i) +b) >=1\n",
    "\n",
    "     Maximize : M = 2 / mod(w)  --> Mininmize : 1/2 (w^T * w)\n",
    "\n",
    "**Solving the Optimization Problem**\n",
    "\n",
    "Find w and b such that,\n",
    "\n",
    "(w) =  (w^T *w) is minimized;\n",
    "\n",
    "and for all {(xi,yi)} :  yi(w^T*x(i)+ b)  1\n",
    "\n",
    "Need to optimize a quadratic function subject to linear constraints.\n",
    "Quadratic optimization problems are a well-known class of mathematical programming problems.\n",
    "The solution involves constructing a dual problem where a Lagrange multiplier is associated with every constraint in the primary problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "F3qAf-x4he9m",
    "outputId": "a9c8a5d7-511a-44e5-c784-84374b690c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[127  15]\n",
      " [ 43  46]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.89      0.81       142\n",
      "          1       0.75      0.52      0.61        89\n",
      "\n",
      "avg / total       0.75      0.75      0.74       231\n",
      "\n",
      "accuracy_score: \n",
      " 0.748917748918\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmclf = svm.SVC(kernel=\"linear\")\n",
    "svmclf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = svmclf.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,y_pred))\n",
    "print('accuracy_score: \\n',svmclf.score(X=X_test,y=y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldZLRSvpkoDl"
   },
   "source": [
    "## Naive Bayes  Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjUy5a8he7PO"
   },
   "source": [
    "It is a probablistic framework for solving the classification problems.It uses the bayes theorem for classification.\n",
    "This method assumes independence among the attributes when the class is given.\n",
    "In the given data all the attributes are numerical  so we can use either discretization or  probablity density estimation  method.\n",
    "\n",
    "The main issue with the naive bayes is for the  outcome when the conditional probablity value is zero. If that happenthen naive bayes will not be able to classify the correct output.(because when we multiply the conditional probablities to find the y value then if one value will be zero then it will affect the whole output ).\n",
    "\n",
    "###SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7g3y10L3NBJ"
   },
   "source": [
    "Because of the given limitations of naive bayes , we have applied the gaussian naive bayes  in our algorithm :\n",
    "### Gaussian naive bayes\n",
    "\n",
    "Naive Bayes can be extended to real-valued attributes, most commonly by assuming a Gaussian distribution. To estimate the distribution of the data, Gaussian (or Normal distribution) is the easiest to work with because you only need to estimate the mean and the standard deviation from your training data.\n",
    "\n",
    "**Representation for Gaussian Naive Bayes**\n",
    "\n",
    "Above, we calculated the probabilities for input values for each class using a frequency. With real-valued inputs, we can calculate the mean and standard deviation of input values (x) for each class to summarize the distribution.\n",
    "\n",
    "**Learn a Gaussian Naive Bayes Model From Data**\n",
    "\n",
    "This is as simple as calculating the mean and standard deviation values of each input variable (x) for each class value.\n",
    "\n",
    "mean(x) = 1/n * sum(x)\n",
    "\n",
    "Where n is the number of instances and x are the values for an input variable in your training data.\n",
    "\n",
    "We can calculate the standard deviation using the following equation:\n",
    "\n",
    "standard deviation(x) = sqrt(1/n * sum(xi-mean(x)^2 ))\n",
    "\n",
    "This is the square root of the average squared difference of each value of x from the mean value of x, where n is the number of instances.\n",
    "\n",
    "**Make Predictions With a Gaussian Naive Bayes Model**\n",
    "\n",
    "Probabilities of new x values are calculated using the Gaussian Probability Density Function (PDF).\n",
    "\n",
    "When making predictions these parameters can be plugged into the Gaussian PDF with a new input for the variable, and in return the Gaussian PDF will provide an estimate of the probability of that new input value for that class.\n",
    "\n",
    "pdf(x, mean, sd) = (1 / (sqrt(2 * PI) * sd)) * exp(-((x-mean^2)/(2*sd^2)))\n",
    "\n",
    "Where pdf(x) is the Gaussian PDF, sqrt() is the square root, mean and sd are the mean and standard deviation calculated above, PI is the numerical constant, exp() is the numerical constant e or Eulers number raised to power and x is the input value for the input variable.\n",
    "\n",
    "We can then plug in the probabilities into the equation above to make predictions with real-valued inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "TSB67fTZkvxm",
    "outputId": "3ef00fe1-823a-4a7e-a5b9-c692f97d931c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[115  27]\n",
      " [ 39  50]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.81      0.78       142\n",
      "          1       0.65      0.56      0.60        89\n",
      "\n",
      "avg / total       0.71      0.71      0.71       231\n",
      "\n",
      "accuracy_score: \n",
      " 0.714285714286\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "from sklearn import naive_bayes\n",
    "nbclf = naive_bayes.GaussianNB()\n",
    "nbclf.fit(X=X_train, y=y_train)\n",
    "y_pred = nbclf.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,y_pred))\n",
    "print('accuracy_score: \\n',nbclf.score(X=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOIvAgVK_5HV"
   },
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvtnVydsfx58"
   },
   "source": [
    "Random Forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It can be used for both classification and regression tasks. \n",
    "** Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction. **\n",
    "Random Forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model.\n",
    "Therefore, in Random Forest, only a random subset of the features is taken into consideration by the algorithm for splitting a node. You can even make trees more random, by additionally using random thresholds for each feature rather than searching for the best possible thresholds (like a normal decision tree does).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "-24v-huP__Fk",
    "outputId": "b03f732a-b756-4f44-fc9d-04363eb4b17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[119  23]\n",
      " [ 46  43]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.84      0.78       142\n",
      "          1       0.65      0.48      0.55        89\n",
      "\n",
      "avg / total       0.69      0.70      0.69       231\n",
      "\n",
      "accuracy_score: \n",
      " 0.701298701299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 4)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,y_pred))\n",
    "print('accuracy_score: \\n',rf.score(X=X_test,y=y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkJi3bxb5So3"
   },
   "source": [
    "# Cross Validation\n",
    "By using cross validation, we will be splitting our dataset into 10 equal parts...We keep one part for testing our algorithm and we train models on the rest...Now these parts that we divided the dataset into, keeps interchanging to form diffrent combinations of training and testing data...We get difffrent accuracy score for each combination...This is done by cross_val_score()..It gives us the list of diffrent accuracies...Now by taking the mean of this score, we can find the general accuracy of our model... This gives a generalised output..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M5cThGohk7kD"
   },
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold =KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "3N2Drifrk-dn",
    "outputId": "1e769e51-acd2-4ecd-889b-88488e3011d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.773411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.750017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.744771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbor</th>\n",
       "      <td>0.714833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree classifier</th>\n",
       "      <td>0.691388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy\n",
       "Support Vector Machine    0.773411\n",
       "Naive Bayes               0.750017\n",
       "Random Forest Classifier  0.744771\n",
       "K Nearest Neighbor        0.714833\n",
       "Decision tree classifier  0.691388"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algos = [\"Support Vector Machine\",\"K Nearest Neighbor\",\"Naive Bayes\",\"Random Forest Classifier\",\"Decision tree classifier\"]\n",
    "clfs = [svm.SVC(kernel=\"linear\"),KNeighborsClassifier(n_neighbors=2),naive_bayes.GaussianNB(),RandomForestClassifier(random_state = 4),tree.DecisionTreeClassifier()]\n",
    "cv_results=[]\n",
    "for classifiers in clfs:\n",
    "    cv_score = cross_val_score(classifiers,features,labels,cv=kfold,scoring=\"accuracy\")\n",
    "    cv_results.append(cv_score.mean())\n",
    "cv_mean = pd.DataFrame(cv_results,index=algos)\n",
    "cv_mean.columns=[\"Accuracy\"]\n",
    "cv_mean.sort_values(by=\"Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lF43fD0UWBJE",
    "08JV0J52Wmhy"
   ],
   "name": "ids_project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
